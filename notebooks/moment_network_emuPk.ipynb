{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import baccoemu\n",
    "import chainconsumer\n",
    "import dynesty\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import emcee\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('/dipc/kstoreyf/muchisimocks/scripts')\n",
    "#import sbi_tools\n",
    "import plot_utils\n",
    "#import scripts\n",
    "# from scripts import sbi_tools\n",
    "#from scripts import plot_utils\n",
    "import generate_emuPks as genP\n",
    "\n",
    "from momentnetworks import demo\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = '../plots/plots_2024-02-19'\n",
    "save_plots = True\n",
    "\n",
    "tag_fit = '_cosmolib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10474737",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpu = cpu_count()\n",
    "print(\"{0} CPUs\".format(ncpu))\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl.pyplot.style.use('default')\n",
    "mpl.pyplot.close('all')\n",
    "\n",
    "font, rcnew = plot_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "mpl.pyplot.rcParams.update(rcnew)\n",
    "mpl.pyplot.style.use('tableau-colorblind10')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "#N_threads = sbi_tools.set_N_threads(6)\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 16 \n",
    "mpl.rcParams['ytick.labelsize'] = 16 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d7912",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_emuPk = '_2param'\n",
    "\n",
    "fn_emuPk = f'../data/emuPks/emuPks{tag_emuPk}.npy'\n",
    "fn_emuPk_params = f'../data/emuPks/emuPks_params{tag_emuPk}.txt'\n",
    "fn_emuk = f'../data/emuPks/emuPks_k{tag_emuPk}.txt'\n",
    "fn_emuPkerrG = f'../data/emuPks/emuPks_errgaussian_{tag_emuPk}.npy'\n",
    "\n",
    "Pk_noiseless = np.load(fn_emuPk)\n",
    "gaussian_error_pk = np.load(fn_emuPkerrG)\n",
    "theta = np.genfromtxt(fn_emuPk_params, delimiter=',', names=True)\n",
    "param_names = theta.dtype.names\n",
    "# from tuples to 2d array\n",
    "theta = np.array([list(tup) for tup in theta])\n",
    "kk = np.genfromtxt(fn_emuk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot = theta.shape[0]\n",
    "n_params = theta.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7897e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pk_noiseless.shape, theta.shape, gaussian_error_pk.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b41c5dc",
   "metadata": {},
   "source": [
    "Add some error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc41182",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "Pk = rng.normal(Pk_noiseless, gaussian_error_pk)\n",
    "# Pk = []\n",
    "# for i in range(n_tot):\n",
    "#     pk = rng.normal(Pk_noiseless[i], gaussian_error_pk[i])\n",
    "#     Pk.append(Pk)\n",
    "# Pk = np.array(Pk)\n",
    "print(Pk.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c9fe6a",
   "metadata": {},
   "source": [
    "Plot P(k) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843917db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(figsize=(6, 4.5))\n",
    "for iLH in range(n_tot):\n",
    "    ax.loglog(kk, gaussian_error_pk[iLH])\n",
    "\n",
    "ax.set_xlabel(r'$k \\,\\, [h \\,\\, {\\rm Mpc}^{-1}]$', fontsize=23)\n",
    "ax.set_ylabel(r'$\\sigma_\\text{G}(k)$', fontsize=23)\n",
    "\n",
    "mpl.pyplot.tight_layout()\n",
    "mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52692bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(figsize=(6, 4.5))\n",
    "for iLH in range(n_tot):\n",
    "    ax.loglog(kk, Pk[iLH])\n",
    "\n",
    "ax.set_xlabel(r'$k \\,\\, [h \\,\\, {\\rm Mpc}^{-1}]$', fontsize=23)\n",
    "ax.set_ylabel(r'$P(k) \\,\\, [h^{-3} \\,\\, {\\rm Mpc}^3]$', fontsize=23)\n",
    "\n",
    "mpl.pyplot.tight_layout()\n",
    "mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_biasmodels = len(biases_vec)\n",
    "n_biasmodels = 0\n",
    "n_cosmos = n_params\n",
    "print(n_biasmodels, n_cosmos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f41673",
   "metadata": {},
   "source": [
    "Split into train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train, p_test = 0.8, 0.1\n",
    "p_val = 1-p_train-p_test\n",
    "train_split = int(theta.shape[0]*p_train)\n",
    "test_split = int(theta.shape[0]*(1-p_test))\n",
    "#train_val_split = int(n_biasmodels*round(theta.shape[0]*0.99/n_biasmodels))\n",
    "\n",
    "theta_train = theta[:train_split]\n",
    "theta_val = theta[train_split:test_split]\n",
    "theta_test = theta[test_split:]\n",
    "print(theta_train.shape, theta_val.shape, theta_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pk_train = Pk[:train_split]\n",
    "Pk_val = Pk[train_split:test_split]\n",
    "Pk_test = Pk[test_split:]\n",
    "\n",
    "mask = np.all(Pk_train>0, axis=0)\n",
    "Pk_train = Pk_train[:,mask]\n",
    "Pk_val = Pk_val[:,mask]\n",
    "Pk_test = Pk_test[:,mask]\n",
    "k = kk[mask]\n",
    "\n",
    "gaussian_error_pk_train = gaussian_error_pk[:train_split][:,mask]\n",
    "gaussian_error_pk_val = gaussian_error_pk[train_split:test_split][:,mask]\n",
    "gaussian_error_pk_test = gaussian_error_pk[test_split:][:,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = Pk_train.shape[1]\n",
    "print(n_tot, n_params, n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41615173",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1,1, figsize=(7,5))\n",
    "fontsize = 24\n",
    "fontsize1 = 18\n",
    "\n",
    "alpha = 0.7\n",
    "\n",
    "tmp_Pk_plot = Pk_train\n",
    "tmp_Pk_plot = tmp_Pk_plot[np.random.choice(tmp_Pk_plot.shape[0], tmp_Pk_plot.shape[0], replace=False)].T\n",
    "ax.plot(np.log10(k), np.log10(tmp_Pk_plot), c='royalblue', alpha=alpha, lw=0.5, label='training set')\n",
    "\n",
    "tmp_Pk_plot = Pk_test\n",
    "tmp_Pk_plot = tmp_Pk_plot[np.random.choice(tmp_Pk_plot.shape[0], tmp_Pk_plot.shape[0], replace=False)].T\n",
    "ax.plot(np.log10(k), np.log10(tmp_Pk_plot), c='k', alpha=alpha, lw=0.5, label='test set')\n",
    "    \n",
    "ax.plot(np.log10(k), np.log10(Pk_test[0]), c='m', alpha=alpha, lw=2, label='test data')\n",
    "    \n",
    "ax.set_xlabel(r'$k \\,\\, [h \\,\\, {\\rm Mpc}^{-1}]$', fontsize=23)\n",
    "ax.set_ylabel(r'$P(k) \\,\\, [h^{-3} \\,\\, {\\rm Mpc}^3]$', fontsize=23)\n",
    "\n",
    "mpl.pyplot.tight_layout()\n",
    "mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55695ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bounds = {}\n",
    "for pp, param_name in enumerate(param_names):\n",
    "    dict_bounds[param_name] = [np.min(theta[:,pp]), np.max(theta[:,pp])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x_train):\n",
    "        self.x_train_min = np.min(x_train)\n",
    "        self.x_train_max = np.max(x_train)\n",
    "\n",
    "    def scale(self, x):\n",
    "        log_x = np.log10(x)\n",
    "        log_x_norm = (log_x - np.log10(self.x_train_min)) / (np.log10(self.x_train_max) - np.log10(self.    x_train_min))\n",
    "        return log_x_norm\n",
    "    \n",
    "    def unscale(self, x_scaled):\n",
    "        x = x_scaled * (np.log10(self.x_train_max) - np.log10(self.x_train_min)) + np.log10(self.x_train_min)\n",
    "        return 10**x  \n",
    "    \n",
    "    def scale_error(self, err, x):\n",
    "        # need 1/np.log(10) factor bc working in base 10\n",
    "        dydx = 1./x * 1/np.log(10) * 1./(np.log10(self.x_train_max) - np.log10(self.x_train_min))\n",
    "        err_scaled = np.sqrt(np.multiply(dydx**2, err**2))\n",
    "        return err_scaled\n",
    "    \n",
    "    def scale_log(self, x):\n",
    "        return np.log10(x)\n",
    "    \n",
    "    def scale_log_error(self, err, x):\n",
    "        return (1./x) * (1/np.log(10)) * err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bdcc83",
   "metadata": {},
   "source": [
    "ok gaussian error is not the same here...! check how bacco is measuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler()\n",
    "scaler.fit(Pk_train)\n",
    "Pk_train_scaled = scaler.scale(Pk_train)\n",
    "Pk_val_scaled = scaler.scale(Pk_val)\n",
    "Pk_test_scaled = scaler.scale(Pk_test)\n",
    "\n",
    "gaussian_error_pk_train_scaled = scaler.scale_error(gaussian_error_pk_train, Pk_train)\n",
    "gaussian_error_pk_val_scaled = scaler.scale_error(gaussian_error_pk_val, Pk_val)\n",
    "gaussian_error_pk_test_scaled = scaler.scale_error(gaussian_error_pk_test, Pk_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ad849",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(Pk_train), np.max(Pk_train))\n",
    "print(np.min(Pk_train_scaled), np.max(Pk_train_scaled))\n",
    "\n",
    "print(np.min(Pk_test), np.max(Pk_test))\n",
    "print(np.min(Pk_test_scaled), np.max(Pk_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3623283",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pk_train.shape, theta_train.shape, n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57705297",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_extra = 0.2*np.std(Pk_train, axis=0)\n",
    "err_extra_scaled = scaler.scale_error(err_extra, np.median(Pk_train, axis=0))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca15d9",
   "metadata": {},
   "source": [
    "### Set up emulator, visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef9785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def setup_cosmo_emu():\n",
    "#     print(\"Setting up emulator cosmology\")\n",
    "#     cosmo_params = {\n",
    "#         #'omega_cold'    :  Om,\n",
    "#         #'sigma8_cold'   :  sigma8, # if A_s is not specified\n",
    "#         'omega_baryon'  :  param_dict_fixed['omega_baryon'],\n",
    "#         'ns'            :  param_dict_fixed['n_s'],\n",
    "#         #'hubble'        :  hubble,\n",
    "#         'neutrino_mass' :  0.0,\n",
    "#         'w0'            : -1.0,\n",
    "#         'wa'            :  0.0,\n",
    "#         'expfactor'     :  1\n",
    "#     }\n",
    "#     return cosmo_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df67709",
   "metadata": {},
   "outputs": [],
   "source": [
    "emu_param_names = param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633cc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emu = baccoemu.Lbias_expansion(verbose=False)\n",
    "fn_emu = '/dipc_storage/cosmosims/data_share/lbias_emulator/lbias_emulator2.0.0'\n",
    "emu = baccoemu.Lbias_expansion(verbose=False, \n",
    "                               nonlinear_emu_path=fn_emu,\n",
    "                               nonlinear_emu_details='details.pickle',\n",
    "                               nonlinear_emu_field_name='NN_n',\n",
    "                               nonlinear_emu_read_rotation=False)\n",
    "#cosmo_params = setup_cosmo_emu()\n",
    "cosmo_params = genP.setup_cosmo_emu()\n",
    "# TODO save and read bias params\n",
    "bias_params = [1., 0., 0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall quantities\n",
    "deltas_pk_per_err = []\n",
    "deltas_pk_per_err_scaled = []\n",
    "for i in range(Pk_train.shape[0]):\n",
    "    # if i % 100 == 0:\n",
    "    #     print(i)\n",
    "    # for pp in range(len(param_names)):\n",
    "    #     cosmo_params[emu_param_names[pp]] = theta[i][pp]\n",
    "    # _, pk_model_unscaled, _ = emu.get_galaxy_real_pk(bias=bias_params, k=k, \n",
    "    #                                                     **cosmo_params)\n",
    "    # in this case the orig emu pks are what we want\n",
    "    pk_model_unscaled = Pk_noiseless[:train_split][i]\n",
    "    delta_pk_per_err = (pk_model_unscaled-Pk_train[i])/gaussian_error_pk_train[i]\n",
    "    deltas_pk_per_err.append(delta_pk_per_err)\n",
    "    \n",
    "    pk_model = scaler.scale(pk_model_unscaled)\n",
    "    delta_pk_per_err_scaled = (pk_model-Pk_train_scaled[i])/gaussian_error_pk_train_scaled[i]\n",
    "    deltas_pk_per_err_scaled.append(delta_pk_per_err_scaled)\n",
    "    \n",
    "deltas_pk_per_err = np.array(deltas_pk_per_err)\n",
    "delta_pk_per_err_16 = np.percentile(deltas_pk_per_err, 16, axis=0)\n",
    "delta_pk_per_err_84 = np.percentile(deltas_pk_per_err, 84, axis=0)\n",
    "\n",
    "deltas_pk_per_err_scaled = np.array(deltas_pk_per_err_scaled)\n",
    "deltas_pk_per_err_scaled_16 = np.percentile(deltas_pk_per_err_scaled, 16, axis=0)\n",
    "deltas_pk_per_err_scaled_84 = np.percentile(deltas_pk_per_err_scaled, 84, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 2, 1\n",
    "fig, axarr = plt.subplots(nrows, ncols, figsize=(6,6), sharex=True, height_ratios=[2,1])\n",
    "plt.subplots_adjust(hspace=0)\n",
    "    \n",
    "# a few examples\n",
    "colors = ['red', 'orange', 'green', 'blue', 'purple']\n",
    "for i in range(5):\n",
    "    for pp in range(len(param_names)):\n",
    "        cosmo_params[emu_param_names[pp]] = theta[i][pp]\n",
    "    _, pk_model_unscaled, _ = emu.get_galaxy_real_pk(bias=bias_params, k=k, \n",
    "                                                        **cosmo_params)\n",
    "\n",
    "    label_true, label_emu, label_stdev = None, None, None\n",
    "    if i==0:\n",
    "        label_true = 'data (map2map)'\n",
    "        label_emu = 'emulated at true theta'\n",
    "        label_stdev = r'$0.2*\\sigma_\\text{stdev}(P_\\text{train}(k))$'\n",
    "    \n",
    "    if i==0:\n",
    "        axarr[0].errorbar(k, Pk_train[i], yerr=gaussian_error_pk_train[i], \n",
    "                          ls='--', marker='o', markersize=6, alpha=0.5, label=label_true, color=colors[i])\n",
    "    else:\n",
    "        axarr[0].plot(k, Pk_train[i], ls='--', marker='o', markersize=6, alpha=0.5, label=label_true, color=colors[i])\n",
    "    axarr[0].plot(k, pk_model_unscaled, ls='-', alpha=0.5, label=label_emu, color=colors[i])\n",
    "    \n",
    "    axarr[1].plot(k, (pk_model_unscaled-Pk_train[i])/gaussian_error_pk_train[i], ls='-', alpha=0.5, color=colors[i])\n",
    "    axarr[1].axhline(0, color='grey', lw=0.5)\n",
    "    axarr[1].fill_between(k, -err_extra/gaussian_error_pk_train[i], \n",
    "                              err_extra/gaussian_error_pk_train[i], color='grey', alpha=0.1)\n",
    "\n",
    "axarr[1].fill_between(k, delta_pk_per_err_16, delta_pk_per_err_84, color='cyan', alpha=0.3,\n",
    "                      label='16-84 percentile of training set')\n",
    "\n",
    "plt.xscale('log')\n",
    "axarr[0].set_yscale('log')\n",
    "    \n",
    "axarr[1].set_ylim(-5, 5)\n",
    "    \n",
    "axarr[0].legend(fontsize=12)\n",
    "axarr[1].legend(fontsize=10)\n",
    "\n",
    "axarr[1].set_xlabel(r'$k \\,\\, [h \\,\\, {\\rm Mpc}^{-1}]$', fontsize=18)\n",
    "axarr[0].set_ylabel(r'$P(k) \\,\\, [h^{-3} \\,\\, {\\rm Mpc}^3]$', fontsize=18)    \n",
    "axarr[1].set_ylabel(r'$(P_\\text{emu}-P_\\text{data})/\\sigma_\\text{G}$', fontsize=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 2, 1\n",
    "fig, axarr = plt.subplots(nrows, ncols, figsize=(6,6), sharex=True, height_ratios=[2,1])\n",
    "plt.subplots_adjust(hspace=0)\n",
    "\n",
    "colors = ['red', 'orange', 'green', 'blue', 'purple']\n",
    "\n",
    "for i in range(5):\n",
    "    for pp in range(len(param_names)):\n",
    "        cosmo_params[emu_param_names[pp]] = theta[i][pp]\n",
    "    _, pk_model_unscaled, _ = emu.get_galaxy_real_pk(bias=bias_params, k=k, \n",
    "                                                        **cosmo_params)\n",
    "    pk_model_scaled = scaler.scale(pk_model_unscaled)\n",
    "    \n",
    "    label_true, label_emu, label_stdev = None, None, None\n",
    "    if i==0:\n",
    "        label_true = 'data (map2map)'\n",
    "        label_emu = 'emulated at true theta'\n",
    "        label_stdev = r'$0.2*\\sigma_\\text{stdev}(P_\\text{train}(k))$'\n",
    "    \n",
    "    if i==0:\n",
    "        axarr[0].errorbar(k, Pk_train_scaled[i], yerr=gaussian_error_pk_train_scaled[i], \n",
    "                          ls='--', marker='o', markersize=6, alpha=0.5, label=label_true, color=colors[i])\n",
    "    else:\n",
    "        axarr[0].plot(k, Pk_train_scaled[i], ls='--', marker='o', markersize=6, alpha=0.5, label=label_true, color=colors[i])\n",
    "    axarr[0].plot(k, pk_model_scaled, ls='-', alpha=0.5, label=label_emu, color=colors[i])\n",
    "    \n",
    "    axarr[1].plot(k, (pk_model_scaled-Pk_train_scaled[i])/gaussian_error_pk_train_scaled[i], ls='-', alpha=0.5, color=colors[i])\n",
    "    axarr[1].axhline(0, color='grey', lw=0.5)    \n",
    "    \n",
    "    axarr[1].fill_between(k, -err_extra_scaled/gaussian_error_pk_train_scaled[i], \n",
    "                              err_extra_scaled/gaussian_error_pk_train_scaled[i], color='grey', alpha=0.1)\n",
    "\n",
    "axarr[1].fill_between(k, deltas_pk_per_err_scaled_16, deltas_pk_per_err_scaled_84, color='cyan', alpha=0.3,\n",
    "                      label='16-84 percentile of training set')\n",
    "\n",
    "plt.xscale('log')\n",
    "#axarr[0].set_yscale('log')\n",
    "    \n",
    "axarr[1].set_ylim(-5, 5)\n",
    "    \n",
    "axarr[0].legend(fontsize=12)\n",
    "axarr[1].legend(fontsize=10)\n",
    "\n",
    "axarr[1].set_xlabel(r'$k \\,\\, [h \\,\\, {\\rm Mpc}^{-1}]$', fontsize=18)\n",
    "axarr[0].set_ylabel(r'$P(k) \\,\\, [h^{-3} \\,\\, {\\rm Mpc}^3]$', fontsize=18)    \n",
    "axarr[1].set_ylabel(r'$(P_\\text{emu}-P_\\text{data})/\\sigma_\\text{G}$', fontsize=18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea6d75",
   "metadata": {},
   "source": [
    "### Set up and run Moment Network model\n",
    "\n",
    "Following demos at https://github.com/NiallJeffrey/MomentNetworks/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = demo.simple_leaky(n_dim, n_params, learning_rate=1e-4) \n",
    "regression = model_instance.model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c770aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(theta_train.shape, Pk_train.shape)\n",
    "print(theta_val.shape, Pk_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5d5ca",
   "metadata": {},
   "source": [
    "Train initial model (basic MLP), as usual, on labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = regression.fit(Pk_train_scaled, theta_train,\n",
    "                         epochs=200, batch_size=32, shuffle=True,\n",
    "                         validation_data=(Pk_val_scaled, theta_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a74c3c",
   "metadata": {},
   "source": [
    "Get means and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_train_pred = regression.predict(np.atleast_2d(Pk_train_scaled))\n",
    "theta_val_pred = regression.predict(np.atleast_2d(Pk_val_scaled))\n",
    "\n",
    "cov_dict = {}\n",
    "\n",
    "training_covariances = []\n",
    "training_covariances_val = []\n",
    "count = 0\n",
    "for i in range(n_params):\n",
    "    for j in range(n_params):\n",
    "        if j<i:\n",
    "            cov_dict[(i,j)] = cov_dict[(j,i)]\n",
    "            continue\n",
    "        training_cov = ((theta_train[:,i]-theta_train_pred[:,i])* \\\n",
    "                        (theta_train[:,j]-theta_train_pred[:,j]))\n",
    "        training_covariances.append(training_cov)\n",
    "        \n",
    "        training_cov_val = ((theta_val[:,i]-theta_val_pred[:,i])* \\\n",
    "                            (theta_val[:,j]-theta_val_pred[:,j]))\n",
    "        training_covariances_val.append(training_cov_val)\n",
    "        \n",
    "        cov_dict[(i,j)] = count\n",
    "        count += 1\n",
    "        \n",
    "training_covariances = np.array(training_covariances).T\n",
    "training_covariances_val = np.array(training_covariances_val).T\n",
    "\n",
    "n_covs = training_covariances.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ccea3",
   "metadata": {},
   "source": [
    "Set up and train model on the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = demo.simple_leaky(n_dim, n_covs, learning_rate=1e-3)\n",
    "regression_var_unknown_mean = model_instance.model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = regression_var_unknown_mean.fit(Pk_train_scaled,\n",
    "                                          training_covariances,\n",
    "                                          epochs=200, batch_size=32, shuffle=True,\n",
    "                                          validation_data = (Pk_val_scaled,\n",
    "                                                             training_covariances_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7a19d",
   "metadata": {},
   "source": [
    "### Set up explicit likelihood, MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for emcee\n",
    "n_burn = 40\n",
    "n_steps = 200 # 50000\n",
    "n_walkers = 4 * n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41381d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for emcee\n",
    "def log_prior(theta):\n",
    "    for pp in range(len(param_names)):\n",
    "       if (theta[pp] < dict_bounds[param_names[pp]][0]) or (theta[pp] >= dict_bounds[param_names[pp]][1]):\n",
    "           return -np.inf\n",
    "    return 0.0\n",
    "\n",
    "# for dynesty\n",
    "def prior_transform(u):\n",
    "\n",
    "    u_transformed = []\n",
    "    for pp in range(len(param_names)):\n",
    "        width = dict_bounds[param_names[pp]][1] - dict_bounds[param_names[pp]][0]\n",
    "        min_bound = dict_bounds[param_names[pp]][0]\n",
    "        \n",
    "        u_t = width*u[pp] + min_bound\n",
    "        u_transformed.append(u_t)           \n",
    "\n",
    "    return np.array(u_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d29a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global pk_data, cov_inv\n",
    "\n",
    "def log_likelihood(theta):\n",
    "    for pp in range(len(param_names)):\n",
    "        cosmo_params[emu_param_names[pp]] = theta[pp]\n",
    "    _, pk_model_unscaled, _ = emu.get_galaxy_real_pk(bias=bias_params, k=k, \n",
    "                                                **cosmo_params)\n",
    "    pk_model = scaler.scale(pk_model_unscaled)\n",
    "    diff = pk_data-pk_model\n",
    "    # print(theta)\n",
    "    # print(cosmo_params)\n",
    "    # print(pk_data)\n",
    "    # print(pk_model)\n",
    "    # print(cov_inv[0,0], cov_inv[1,1], cov_inv[2,2])\n",
    "    # print(-0.5*np.dot(diff,np.dot(cov_inv,diff)))\n",
    "    \n",
    "    # print()\n",
    "    return -0.5*np.dot(diff,np.dot(cov_inv,diff))\n",
    "\n",
    "def log_posterior(theta):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91523c50",
   "metadata": {},
   "source": [
    "### Test on a model from the test set (held-out data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_test = 0\n",
    "pk_data = Pk_test_scaled[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38eca61",
   "metadata": {},
   "source": [
    "Moment network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mean_obs_test = regression.predict(np.atleast_2d(pk_data))\n",
    "predicted_var_obs_test = (regression_var_unknown_mean.predict(np.atleast_2d(pk_data))[0])\n",
    "\n",
    "moment_network_param_cov_test = np.empty((n_params, n_params))\n",
    "\n",
    "for i in range(n_params):\n",
    "    for j in range(n_params):\n",
    "        moment_network_param_cov_test[i,j] = predicted_var_obs_test[cov_dict[(i,j)]]\n",
    "print(moment_network_param_cov_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_network_samples_test = np.array(np.random.multivariate_normal(predicted_mean_obs_test[0],\n",
    "                                  moment_network_param_cov_test,int(1e6)),dtype=np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394aa32",
   "metadata": {},
   "source": [
    "Explicit likelihood setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d65bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_gaussian_scaled = gaussian_error_pk_test_scaled[idx_test]\n",
    "var = err_gaussian_scaled**2\n",
    "#var = err_gaussian_scaled**2 + err_extra_scaled**2\n",
    "cov_inv = np.diag(1/var)\n",
    "\n",
    "n_threads = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf25582",
   "metadata": {},
   "source": [
    "MCMC, Dynesty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb34779",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dynesty.pool.Pool(n_threads, log_likelihood, prior_transform) as pool:\n",
    "    sampler_test = dynesty.NestedSampler(pool.loglike, pool.prior_transform, n_params, \n",
    "                                         nlive=20, bound='single')\n",
    "    sampler_test.run_nested(dlogz=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e11282",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = sampler_test.results\n",
    "samples_dynesty_test = results_test.samples_equal()\n",
    "print(samples_dynesty_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20f4bf",
   "metadata": {},
   "source": [
    "MCMC, emcee:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "theta_0 = np.array([[rng.uniform(low=dict_bounds[param_name][0],high=dict_bounds[param_name][1]) \n",
    "                     for param_name in param_names] for _ in range(n_walkers)])\n",
    "\n",
    "start = time.time()\n",
    "if n_threads>1:\n",
    "    with Pool(processes=n_threads) as pool:\n",
    "        sampler_emcee = emcee.EnsembleSampler(n_walkers, n_params, log_posterior, pool=pool)\n",
    "        _ = sampler_emcee.run_mcmc(theta_0, n_steps, progress=True) \n",
    "else:\n",
    "    sampler_emcee = emcee.EnsembleSampler(n_walkers, n_params, log_posterior)\n",
    "    _ = sampler_emcee.run_mcmc(theta_0, n_steps, progress=True) \n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time: {end-start} s ({(end-start)/60} min)\")\n",
    "\n",
    "samples_emcee = sampler_emcee.get_chain(discard=n_burn, flat=True, thin=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36863d4",
   "metadata": {},
   "source": [
    "### Plot contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_label_dict = {'omega_cold': r'$\\Omega_\\mathrm{m}$',\n",
    "                'sigma8_cold': r'$\\sigma_{8}$',\n",
    "                'sigma_8': r'$\\sigma_{8}$',\n",
    "                'hubble': r'$h$',\n",
    "                'h': r'$h$',\n",
    "                'ns': r'$n_\\mathrm{s}$',\n",
    "                'n_s': r'$n_\\mathrm{s}$',\n",
    "                'omega_baryon': r'$\\Omega_\\mathrm{b}$',}\n",
    "param_labels = [param_label_dict[param_name] for param_name in param_names]\n",
    "extents = [dict_bounds[param_name] for param_name in param_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = chainconsumer.ChainConsumer()\n",
    "\n",
    "c.add_chain(chainconsumer.Chain(\n",
    "            samples=pd.DataFrame(moment_network_samples_test, columns=param_names),\n",
    "            name='Moment Network', color='blue')\n",
    "            )\n",
    "\n",
    "c.add_chain(chainconsumer.Chain(\n",
    "            samples=pd.DataFrame(samples_emcee, columns=param_names),\n",
    "            name='MCMC (emcee)', color='purple', ls='--',\n",
    "            smooth=1, bins=10)\n",
    "            )\n",
    "\n",
    "c.add_chain(chainconsumer.Chain(\n",
    "            samples=pd.DataFrame(samples_dynesty_test, columns=param_names),\n",
    "            name='MCMC (Dynesty)', color='green', \n",
    "            smooth=2, bins=5)\n",
    "            )\n",
    "\n",
    "c.set_plot_config(\n",
    "    chainconsumer.PlotConfig(\n",
    "        flip=True,\n",
    "        labels=param_label_dict,\n",
    "        contour_label_font_size=12,\n",
    "        #extents=dict_bounds,\n",
    "    )\n",
    ")\n",
    "\n",
    "truth_loc = dict(zip(param_names, theta_test[idx_test]))\n",
    "c.add_truth(chainconsumer.Truth(location=truth_loc))\n",
    "\n",
    "fig = c.plotter.plot(figsize = (5,4) )\n",
    "if save_plots:\n",
    "    plt.savefig(f'{plot_dir}/contours_test{idx_test}{tag_emuPk}{tag_fit}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb8ece",
   "metadata": {},
   "source": [
    "### Try another test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_test = 17\n",
    "pk_data = Pk_test_scaled[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d7b02",
   "metadata": {},
   "source": [
    "Moment network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1065de",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mean_obs_test = regression.predict(np.atleast_2d(pk_data))\n",
    "predicted_var_obs_test = (regression_var_unknown_mean.predict(np.atleast_2d(pk_data))[0])\n",
    "\n",
    "moment_network_param_cov_test = np.empty((n_params, n_params))\n",
    "\n",
    "for i in range(n_params):\n",
    "    for j in range(n_params):\n",
    "        moment_network_param_cov_test[i,j] = predicted_var_obs_test[cov_dict[(i,j)]]\n",
    "print(moment_network_param_cov_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_network_samples_test = np.array(np.random.multivariate_normal(predicted_mean_obs_test[0],\n",
    "                                  moment_network_param_cov_test,int(1e6)),dtype=np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e393bfd7",
   "metadata": {},
   "source": [
    "Explicit likelihood setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_gaussian_scaled = gaussian_error_pk_test_scaled[idx_test]\n",
    "var = err_gaussian_scaled**2\n",
    "#var = err_gaussian_scaled**2 + err_extra_scaled**2\n",
    "cov_inv = np.diag(1/var)\n",
    "\n",
    "n_threads = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61cc778",
   "metadata": {},
   "source": [
    "MCMC, Dynesty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c19b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dynesty.pool.Pool(n_threads, log_likelihood, prior_transform) as pool:\n",
    "    sampler_test = dynesty.NestedSampler(pool.loglike, pool.prior_transform, n_params, \n",
    "                                         nlive=20, bound='single')\n",
    "    sampler_test.run_nested(dlogz=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ee7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = sampler_test.results\n",
    "samples_dynesty_test = results_test.samples_equal()\n",
    "print(samples_dynesty_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07636c1c",
   "metadata": {},
   "source": [
    "MCMC, emcee:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aeabb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.default_rng(seed=42)\n",
    "# theta_0 = np.array([[rng.uniform(low=dict_bounds[param_name][0],high=dict_bounds[param_name][1]) \n",
    "#                      for param_name in param_names] for _ in range(n_walkers)])\n",
    "\n",
    "# start = time.time()\n",
    "# if n_threads>1:\n",
    "#     with Pool(processes=n_threads) as pool:\n",
    "#         sampler_emcee = emcee.EnsembleSampler(n_walkers, n_params, log_posterior, pool=pool)\n",
    "#         _ = sampler_emcee.run_mcmc(theta_0, n_steps, progress=True) \n",
    "# else:\n",
    "#     sampler_emcee = emcee.EnsembleSampler(n_walkers, n_params, log_posterior)\n",
    "#     _ = sampler_emcee.run_mcmc(theta_0, n_steps, progress=True) \n",
    "# end = time.time()\n",
    "\n",
    "# print(f\"Time: {end-start} s ({(end-start)/60} min)\")\n",
    "\n",
    "# samples_emcee = sampler_emcee.get_chain(discard=n_burn, flat=True, thin=1)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac8c41",
   "metadata": {},
   "source": [
    "### Plot contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f68815",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_label_dict = {'omega_cold': r'$\\Omega_\\mathrm{m}$',\n",
    "                'sigma8_cold': r'$\\sigma_{8}$',\n",
    "                'sigma_8': r'$\\sigma_{8}$',\n",
    "                'hubble': r'$h$',\n",
    "                'h': r'$h$',\n",
    "                'ns': r'$n_\\mathrm{s}$',\n",
    "                'n_s': r'$n_\\mathrm{s}$',\n",
    "                'omega_baryon': r'$\\Omega_\\mathrm{b}$',}\n",
    "param_labels = [param_label_dict[param_name] for param_name in param_names]\n",
    "extents = [dict_bounds[param_name] for param_name in param_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7455963",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = chainconsumer.ChainConsumer()\n",
    "\n",
    "c.add_chain(chainconsumer.Chain(\n",
    "            samples=pd.DataFrame(moment_network_samples_test, columns=param_names),\n",
    "            name='Moment Network', color='blue')\n",
    "            )\n",
    "\n",
    "# c.add_chain(chainconsumer.Chain(\n",
    "#             samples=pd.DataFrame(samples_emcee, columns=param_names),\n",
    "#             name='MCMC (emcee)', color='purple', ls='--',\n",
    "#             smooth=1, bins=10)\n",
    "#             )\n",
    "\n",
    "c.add_chain(chainconsumer.Chain(\n",
    "            samples=pd.DataFrame(samples_dynesty_test, columns=param_names),\n",
    "            name='MCMC (Dynesty)', color='green', \n",
    "            smooth=2, bins=5)\n",
    "            )\n",
    "\n",
    "c.set_plot_config(\n",
    "    chainconsumer.PlotConfig(\n",
    "        flip=True,\n",
    "        labels=param_label_dict,\n",
    "        contour_label_font_size=12,\n",
    "        #extents=dict_bounds,\n",
    "    )\n",
    ")\n",
    "\n",
    "truth_loc = dict(zip(param_names, theta_test[idx_test]))\n",
    "c.add_truth(chainconsumer.Truth(location=truth_loc))\n",
    "\n",
    "fig = c.plotter.plot(figsize = (5,4) )\n",
    "if save_plots:\n",
    "    plt.savefig(f'{plot_dir}/contours_test{idx_test}{tag_emuPk}{tag_fit}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107a05c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bemuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

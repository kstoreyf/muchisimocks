{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "\n",
    "import scripts\n",
    "from scripts import sbi_tools\n",
    "from scripts import plot_utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.pyplot.style.use('default')\n",
    "mpl.pyplot.close('all')\n",
    "\n",
    "font, rcnew = plot_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "mpl.pyplot.rcParams.update(rcnew)\n",
    "mpl.pyplot.style.use('tableau-colorblind10')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "N_threads = sbi_tools.set_N_threads(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52692bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_script_dir = \"..\"\n",
    "\n",
    "biases_vec = np.loadtxt(os.path.join(path_script_dir, \"data\", \"biases_vec.txt\"))\n",
    "\n",
    "indicesLH = []\n",
    "for ii, dir_name in enumerate(os.listdir(os.path.join(path_script_dir, \"data/biased_pks\"))):\n",
    "    if dir_name.split('_')[0] == \"biased\":\n",
    "        indicesLH.append(int(dir_name.split('_')[4]))\n",
    "indicesLH = np.array(indicesLH)\n",
    "indicesLH = np.unique(indicesLH)\n",
    "\n",
    "#indicesLH = indicesLH[0:1]\n",
    "\n",
    "fig, ax = mpl.pyplot.subplots(figsize=(8, 6))\n",
    "Pk = []\n",
    "for iLH in range(len(indicesLH)):\n",
    "    for ib in range(len(biases_vec)):\n",
    "        kk, tmp_pk = np.loadtxt(os.path.join(\n",
    "            path_script_dir, \"data/biased_pks\", 'biased_pk_m2m_num_%04d_bias_num_%d.txt'%(indicesLH[iLH], ib)\n",
    "        ), unpack=True)\n",
    "        Pk.append(tmp_pk)\n",
    "        mask = tmp_pk > 0\n",
    "        ax.loglog(kk[mask], tmp_pk[mask], label='bias %d'%ib)\n",
    "Pk = np.array(Pk)\n",
    "print(Pk.shape)\n",
    "\n",
    "ax.set_xlabel(r'$k \\,\\, [h \\,\\, {\\rm Mpc}^{-1}]$', fontsize=23)\n",
    "ax.set_ylabel(r'$P(k) \\,\\, [h^{-3} \\,\\, {\\rm Mpc}^3]$', fontsize=23)\n",
    "\n",
    "mpl.pyplot.tight_layout()\n",
    "mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbca31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_read_theta = \"/dipc_storage/mpelle/Yin_data/Quijote\"\n",
    "\n",
    "theta = []\n",
    "for iLH, id_LH in enumerate(indicesLH):\n",
    "    theta.append(np.loadtxt(\n",
    "        os.path.join(\n",
    "            path_read_theta, \"LH\" + str(id_LH).zfill(4), \"param_\"+str(id_LH).zfill(4)+\".txt\")\n",
    "    ))\n",
    "theta = np.array(theta)\n",
    "theta = np.repeat(theta, 10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef68b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_biasmodels = len(biases_vec)\n",
    "n_cosmos = int(theta.shape[0]/n_biasmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=533)\n",
    "n_tot = len(Pk)\n",
    "\n",
    "i_blocks = np.arange(n_tot).reshape(n_cosmos, n_biasmodels)\n",
    "\n",
    "i_shuffle_blocks = rng.choice(np.arange(n_cosmos), replace=False, size=n_cosmos)\n",
    "\n",
    "i_shuffle = i_blocks[i_shuffle_blocks].flatten()\n",
    "\n",
    "Pk = Pk[i_shuffle]\n",
    "theta = theta[i_shuffle]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = int(n_biasmodels*round(theta.shape[0]*0.99/n_biasmodels))\n",
    "\n",
    "theta_train = theta[:train_val_split]\n",
    "theta_test = theta[train_val_split:]\n",
    "print(theta_train.shape, theta_test.shape)\n",
    "\n",
    "Pk_train = Pk[:train_val_split]\n",
    "Pk_test = Pk[train_val_split:]\n",
    "\n",
    "mask = np.all(Pk_train>0, axis=0)\n",
    "Pk_train = Pk_train[:,mask]\n",
    "Pk_test = Pk_test[:,mask]\n",
    "k = kk[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ONE TRAINING SAMPLE\n",
    "# Pk_train = Pk_train[:1]\n",
    "# theta_train = theta_train[:1]\n",
    "# print(Pk_train.shape)\n",
    "# print(theta_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41615173",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1,1, figsize=(7,5))\n",
    "fontsize = 24\n",
    "fontsize1 = 18\n",
    "\n",
    "alpha = 1\n",
    "\n",
    "tmp_Pk_plot = Pk_train\n",
    "tmp_Pk_plot = tmp_Pk_plot[np.random.choice(tmp_Pk_plot.shape[0], tmp_Pk_plot.shape[0], replace=False)].T\n",
    "ax.plot(np.log10(k), np.log10(tmp_Pk_plot), c='royalblue', alpha=alpha, lw=0.5)\n",
    "\n",
    "tmp_Pk_plot = Pk_test\n",
    "tmp_Pk_plot = tmp_Pk_plot[np.random.choice(tmp_Pk_plot.shape[0], tmp_Pk_plot.shape[0], replace=False)].T\n",
    "ax.plot(np.log10(k), np.log10(tmp_Pk_plot), c='k', alpha=alpha, lw=0.5)\n",
    "    \n",
    "mpl.pyplot.tight_layout()\n",
    "mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55695ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bounds = {\n",
    "    'omega_m'    :  [np.min(theta, axis=0)[0], np.max(theta, axis=0)[0]],\n",
    "    'omega_b'    :  [np.min(theta, axis=0)[1], np.max(theta, axis=0)[1]],\n",
    "    'hubble'     :  [np.min(theta, axis=0)[2], np.max(theta, axis=0)[2]],\n",
    "    'ns'         :  [np.min(theta, axis=0)[3], np.max(theta, axis=0)[3]],\n",
    "    'sigma8'     :  [np.min(theta, axis=0)[4], np.max(theta, axis=0)[4]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler:\n",
    "\n",
    "    def __init__(self):\n",
    "          pass\n",
    "        \n",
    "    def fit(self, x_train):\n",
    "        self.x_train_min = np.min(x_train)\n",
    "        self.x_train_max = np.max(x_train)\n",
    "           \n",
    "    def scale(self, x):\n",
    "        log_x = np.log10(x)\n",
    "        log_x_norm = (log_x - np.log10(self.x_train_min)) / (np.log10(self.x_train_max) - np.log10(self.x_train_min))\n",
    "        return log_x_norm\n",
    "    \n",
    "    def unscale(self, x_scaled):\n",
    "        x = x_scaled * (np.log10(self.x_train_max) - np.log10(self.x_train_min)) + np.log10(self.x_train_min)\n",
    "        return 10**x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler()\n",
    "scaler.fit(Pk_train)\n",
    "Pk_train_scaled = scaler.scale(Pk_train)\n",
    "Pk_test_scaled = scaler.scale(Pk_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ad849",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(Pk_train), np.max(Pk_train))\n",
    "print(np.min(Pk_train_scaled), np.max(Pk_train_scaled))\n",
    "\n",
    "print(np.min(Pk_test), np.max(Pk_test))\n",
    "print(np.min(Pk_test_scaled), np.max(Pk_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3623283",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pk_train.shape)\n",
    "print(theta_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ae30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference, posterior = sbi_tools.train_model(\n",
    "    theta_train,\n",
    "    Pk_train_scaled,\n",
    "    prior= sbi_tools.get_prior(dict_bounds),\n",
    "    training_batch_size=16,\n",
    "    validation_fraction=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca4831",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_train_check = theta_train[:1]\n",
    "Pk_train_scaled_check = Pk_train_scaled[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ posterior inference ------------------ #\n",
    "\n",
    "# norm_xx_test = scaler.transform(xx_test)\n",
    "\n",
    "inferred_theta_train_check = sbi_tools.sample_posteriors_theta_test(\n",
    "    posterior,\n",
    "    Pk_train_scaled_check,\n",
    "    dict_bounds,\n",
    "    N_samples=1000\n",
    ")\n",
    "\n",
    "# ------------------ rank stats ------------------ #\n",
    "\n",
    "ranks_train_check = sbi_tools.compute_ranks(theta_train_check, inferred_theta_train_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a127d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_examples = 1\n",
    "\n",
    "custom_titles = [\n",
    "    r'$\\Omega_\\mathrm{m}$',\n",
    "    r'$\\Omega_\\mathrm{b}$',\n",
    "    r'$h$',\n",
    "    r'$n_\\mathrm{s}$',\n",
    "    r'$\\sigma_{8}$'\n",
    "]\n",
    "\n",
    "colors = plot_utils.get_N_colors(N_examples, mpl.colormaps['prism'])\n",
    "for ii_sample in range(N_examples):\n",
    "    fig, axs = plot_utils.corner_plot(\n",
    "        theta_train_check[ii_sample],\n",
    "        inferred_theta_train_check[ii_sample],\n",
    "        custom_titles,\n",
    "        dict_bounds,\n",
    "        color_infer=colors[ii_sample]\n",
    "    )\n",
    "    mpl.pyplot.show()\n",
    "    \n",
    "#fig.save(\"popopo.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior_sample = posterior.sample((1,))\n",
    "# print(posterior_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7edd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ posterior inference ------------------ #\n",
    "\n",
    "# norm_xx_test = scaler.transform(xx_test)\n",
    "\n",
    "inferred_theta_test = sbi_tools.sample_posteriors_theta_test(\n",
    "    posterior,\n",
    "    Pk_test_scaled,\n",
    "    dict_bounds,\n",
    "    N_samples=1000\n",
    ")\n",
    "\n",
    "# ------------------ rank stats ------------------ #\n",
    "\n",
    "ranks = sbi_tools.compute_ranks(theta_test, inferred_theta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_inferred_xx_test = sbi_data_utils.compute_baccoemu_predictions_batch(\n",
    "#     inferred_theta_train_check[indexes],\n",
    "#     list(dict_bounds.keys())\n",
    "# )\n",
    "\n",
    "# fig, ax, ax_res = plot_utils.plot_xx_from_sampled_posteriors(xx_test[indexes], tmp_inferred_xx_test, kk)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a21c9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_examples = 2\n",
    "\n",
    "custom_titles = [\n",
    "    r'$\\Omega_\\mathrm{m}$',\n",
    "    r'$\\Omega_\\mathrm{b}$',\n",
    "    r'$h$',\n",
    "    r'$n_\\mathrm{s}$',\n",
    "    r'$\\sigma_{8}$'\n",
    "]\n",
    "\n",
    "colors = plot_utils.get_N_colors(N_examples, mpl.colormaps['prism'])\n",
    "for ii_sample in range(N_examples):\n",
    "    fig, axs = plot_utils.corner_plot(\n",
    "        theta_test[ii_sample],\n",
    "        inferred_theta_test[ii_sample],\n",
    "        custom_titles,\n",
    "        dict_bounds,\n",
    "        color_infer=colors[ii_sample]\n",
    "    )\n",
    "    mpl.pyplot.show()\n",
    "    \n",
    "#fig.save(\"popopo.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71820921",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_utils.plot_parameter_prediction_vs_truth(inferred_theta_test, theta_test, custom_titles)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_utils.plot_rank_statistcis(ranks, inferred_theta_test.shape[1], custom_titles)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d30d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bbecd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

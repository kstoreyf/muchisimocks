{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import baccoemu\n",
    "import chainconsumer\n",
    "import dynesty\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import emcee\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('/dipc/kstoreyf/muchisimocks/scripts')\n",
    "#import sbi_tools\n",
    "import plot_utils\n",
    "#import scripts\n",
    "# from scripts import sbi_tools\n",
    "#from scripts import plot_utils\n",
    "import generate_emuPks as genP\n",
    "\n",
    "from momentnetworks import demo\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = '../plots/plots_2024-02-19'\n",
    "save_plots = True\n",
    "\n",
    "tag_fit = '_cosmolib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10474737",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpu = cpu_count()\n",
    "print(\"{0} CPUs\".format(ncpu))\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl.pyplot.style.use('default')\n",
    "mpl.pyplot.close('all')\n",
    "\n",
    "font, rcnew = plot_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "mpl.pyplot.rcParams.update(rcnew)\n",
    "mpl.pyplot.style.use('tableau-colorblind10')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "#N_threads = sbi_tools.set_N_threads(6)\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 16 \n",
    "mpl.rcParams['ytick.labelsize'] = 16 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d7912",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names_all = ['omega_cold', 'sigma_8', 'h', 'omega_baryon', 'n_s', 'seed']\n",
    "param_names = ['omega_cold', 'sigma_8', 'h']\n",
    "param_names_fixed = [name for name in param_names_all if name not in param_names]\n",
    "idxs_param_names = [param_names_all.index(name) for name in param_names]\n",
    "\n",
    "#tag_pk = '_b1only'\n",
    "tag_pk = '_b0000'\n",
    "dir_pks = f'../data/pks_cosmolib/pks{tag_pk}'\n",
    "\n",
    "n_lib = 500\n",
    "dir_mocks = '../data/cosmolib'\n",
    "theta = []\n",
    "Pk = []\n",
    "gaussian_error_pk = []\n",
    "param_dict_fixed = {}\n",
    "for idx_LH in range(n_lib):\n",
    "    fn_fields = f'{dir_mocks}/LH{idx_LH}/Eulerian_fields_lr_{idx_LH}.npy'\n",
    "    fn_params = f'{dir_mocks}/LH{idx_LH}/cosmo_{idx_LH}.txt'\n",
    "    fn_pk = f'{dir_pks}/pk_{idx_LH}.npy'\n",
    "    \n",
    "    pk_obj = np.load(fn_pk, allow_pickle=True).item()\n",
    "    Pk.append(pk_obj['pk'])\n",
    "    gaussian_error_pk.append(pk_obj['pk_gaussian_error'])\n",
    "    \n",
    "    param_vals = np.loadtxt(fn_params)\n",
    "    if idx_LH==0:\n",
    "        for name in param_names_fixed:\n",
    "            param_dict_fixed[name] = param_vals[param_names_all.index(name)]\n",
    "    theta.append(param_vals[idxs_param_names])\n",
    "\n",
    "Pk = np.array(Pk)\n",
    "theta = np.array(theta)\n",
    "gaussian_error_pk = np.array(gaussian_error_pk)\n",
    "\n",
    "kk = pk_obj['k'] # all ks should be same so just grab one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7897e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pk.shape, theta.shape, gaussian_error_pk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b23fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_oob = theta[:,param_names.index('sigma_8')] < 0.73\n",
    "# print(np.sum(i_oob), len(i_oob))\n",
    "# print(np.min(theta[:,param_names.index('sigma_8')]), np.max(theta[:,param_names.index('sigma_8')] ))\n",
    "\n",
    "# # if wan't to run on a subset, edit n_samples here (max=1000 right now)\n",
    "# n_samples = n_lib\n",
    "# Pk = Pk[~i_oob][:n_samples]\n",
    "# theta = theta[~i_oob][:n_samples]\n",
    "\n",
    "n_samples = n_lib\n",
    "Pk = Pk[:n_samples]\n",
    "theta = theta[:n_samples]\n",
    "gaussian_error_pk = gaussian_error_pk[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pk.shape, theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e20895",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot = theta.shape[0]\n",
    "n_params = theta.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c9fe6a",
   "metadata": {},
   "source": [
    "Plot P(k) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52692bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(figsize=(6, 4.5))\n",
    "for iLH in range(n_tot):\n",
    "    ax.loglog(kk, Pk[iLH])\n",
    "\n",
    "ax.set_xlabel(r'$k \\,\\, [h \\,\\, {\\rm Mpc}^{-1}]$', fontsize=23)\n",
    "ax.set_ylabel(r'$P(k) \\,\\, [h^{-3} \\,\\, {\\rm Mpc}^3]$', fontsize=23)\n",
    "\n",
    "mpl.pyplot.tight_layout()\n",
    "mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_biasmodels = len(biases_vec)\n",
    "n_biasmodels = 0\n",
    "n_cosmos = n_params\n",
    "print(n_biasmodels, n_cosmos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f41673",
   "metadata": {},
   "source": [
    "Split into train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train, p_test = 0.8, 0.1\n",
    "p_val = 1-p_train-p_test\n",
    "train_split = int(theta.shape[0]*p_train)\n",
    "test_split = int(theta.shape[0]*(1-p_test))\n",
    "#train_val_split = int(n_biasmodels*round(theta.shape[0]*0.99/n_biasmodels))\n",
    "\n",
    "theta_train = theta[:train_split]\n",
    "theta_val = theta[train_split:test_split]\n",
    "theta_test = theta[test_split:]\n",
    "print(theta_train.shape, theta_val.shape, theta_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cad46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise \n",
    "# Pk_train = Pk[:train_split]\n",
    "# err_1p = 0.01*np.mean(Pk_train, axis=0)\n",
    "# rng = np.random.default_rng()\n",
    "# Pk += rng.normal(loc=0, scale=err_1p, size=Pk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pk_train = Pk[:train_split]\n",
    "Pk_val = Pk[train_split:test_split]\n",
    "Pk_test = Pk[test_split:]\n",
    "\n",
    "mask = np.all(Pk_train>0, axis=0)\n",
    "Pk_train = Pk_train[:,mask]\n",
    "Pk_val = Pk_val[:,mask]\n",
    "Pk_test = Pk_test[:,mask]\n",
    "k = kk[mask]\n",
    "\n",
    "gaussian_error_pk_train = gaussian_error_pk[:train_split][:,mask]\n",
    "gaussian_error_pk_val = gaussian_error_pk[train_split:test_split][:,mask]\n",
    "gaussian_error_pk_test = gaussian_error_pk[test_split:][:,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = Pk_train.shape[1]\n",
    "print(n_tot, n_params, n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41615173",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1,1, figsize=(7,5))\n",
    "fontsize = 24\n",
    "fontsize1 = 18\n",
    "\n",
    "alpha = 1\n",
    "\n",
    "tmp_Pk_plot = Pk_train\n",
    "tmp_Pk_plot = tmp_Pk_plot[np.random.choice(tmp_Pk_plot.shape[0], tmp_Pk_plot.shape[0], replace=False)].T\n",
    "ax.plot(np.log10(k), np.log10(tmp_Pk_plot), c='royalblue', alpha=alpha, lw=0.5, label='training set')\n",
    "\n",
    "tmp_Pk_plot = Pk_test\n",
    "tmp_Pk_plot = tmp_Pk_plot[np.random.choice(tmp_Pk_plot.shape[0], tmp_Pk_plot.shape[0], replace=False)].T\n",
    "ax.plot(np.log10(k), np.log10(tmp_Pk_plot), c='k', alpha=alpha, lw=0.5, label='test set')\n",
    "    \n",
    "ax.set_xlabel(r'$k \\,\\, [h \\,\\, {\\rm Mpc}^{-1}]$', fontsize=23)\n",
    "ax.set_ylabel(r'$P(k) \\,\\, [h^{-3} \\,\\, {\\rm Mpc}^3]$', fontsize=23)\n",
    "\n",
    "mpl.pyplot.tight_layout()\n",
    "mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55695ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bounds = {}\n",
    "for pp, param_name in enumerate(param_names):\n",
    "    dict_bounds[param_name] = [np.min(theta[:,pp]), np.max(theta[:,pp])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler:\n",
    "\n",
    "    def __init__(self):\n",
    "          pass\n",
    "        \n",
    "    def fit(self, x_train):\n",
    "        self.x_train_min = np.min(x_train)\n",
    "        self.x_train_max = np.max(x_train)\n",
    "           \n",
    "    def scale(self, x):\n",
    "        log_x = np.log10(x)\n",
    "        log_x_norm = (log_x - np.log10(self.x_train_min)) / (np.log10(self.x_train_max) - np.log10(self.x_train_min))\n",
    "        return log_x_norm\n",
    "    \n",
    "    def unscale(self, x_scaled):\n",
    "        x = x_scaled * (np.log10(self.x_train_max) - np.log10(self.x_train_min)) + np.log10(self.x_train_min)\n",
    "        return 10**x  \n",
    "    \n",
    "    def scale_error(self, err, x):\n",
    "        # need 1/np.log(10) factor bc working in base 10\n",
    "        #print(err[:,0])\n",
    "        dydx = 1./x * 1/np.log(10) * 1./(np.log10(self.x_train_max) - np.log10(self.x_train_min))\n",
    "        #print(dydx[:,0])\n",
    "        #print((dydx**2).shape)\n",
    "        #print((err**2).shape)\n",
    "        #print(np.multiply(dydx**2, err**2)[:,0])\n",
    "        \n",
    "        #print(dydx.shape, err.shape)\n",
    "        mult = (dydx*err)\n",
    "        #print(mult.shape)\n",
    "        #print(mult[:,0])\n",
    "        err_scaled = np.sqrt(np.multiply(dydx**2, err**2))\n",
    "        #print(err_scaled[:,0])\n",
    "        return err_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bdcc83",
   "metadata": {},
   "source": [
    "uh, error is always the same when scaled.... by construction w log?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "25458.80421554*3.46969057e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "12263.69676411*7.20289930e-06, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler()\n",
    "scaler.fit(Pk_train)\n",
    "scaler.scale_error(gaussian_error_pk_train[:2], Pk_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler()\n",
    "scaler.fit(Pk_train)\n",
    "Pk_train_scaled = scaler.scale(Pk_train)\n",
    "Pk_val_scaled = scaler.scale(Pk_val)\n",
    "Pk_test_scaled = scaler.scale(Pk_test)\n",
    "\n",
    "gaussian_error_pk_train_scaled = scaler.scale_error(gaussian_error_pk_train, Pk_train)\n",
    "gaussian_error_pk_val_scaled = scaler.scale_error(gaussian_error_pk_val, Pk_val)\n",
    "gaussian_error_pk_test_scaled = scaler.scale_error(gaussian_error_pk_test, Pk_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ad849",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(Pk_train), np.max(Pk_train))\n",
    "print(np.min(Pk_train_scaled), np.max(Pk_train_scaled))\n",
    "\n",
    "print(np.min(Pk_test), np.max(Pk_test))\n",
    "print(np.min(Pk_test_scaled), np.max(Pk_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3623283",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pk_train.shape)\n",
    "print(theta_train.shape)\n",
    "print(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea6d75",
   "metadata": {},
   "source": [
    "### Set up and run Moment Network model\n",
    "\n",
    "Following demos at https://github.com/NiallJeffrey/MomentNetworks/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = demo.simple_leaky(n_dim, n_params, learning_rate=1e-4) \n",
    "regression = model_instance.model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c770aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(theta_train.shape, Pk_train.shape)\n",
    "print(theta_val.shape, Pk_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5d5ca",
   "metadata": {},
   "source": [
    "Train initial model (basic MLP), as usual, on labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = regression.fit(Pk_train_scaled, theta_train,\n",
    "                         epochs=200, batch_size=32, shuffle=True,\n",
    "                         validation_data=(Pk_val_scaled, theta_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2fed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_mean = regression.predict(np.atleast_2d(Pk_train_scaled)) # maybe should be train & val??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a74c3c",
   "metadata": {},
   "source": [
    "Get means and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_train_pred = regression.predict(np.atleast_2d(Pk_train_scaled))\n",
    "theta_val_pred = regression.predict(np.atleast_2d(Pk_val_scaled))\n",
    "\n",
    "cov_dict = {}\n",
    "\n",
    "training_var_unknown_mean = []\n",
    "training_var_unknown_mean_val = []\n",
    "count = 0\n",
    "for i in range(n_params):\n",
    "    for j in range(n_params):\n",
    "        if j<i:\n",
    "            cov_dict[(i,j)] = cov_dict[(j,i)]\n",
    "            continue\n",
    "        training_covariance = ((theta_train[:,i]-theta_train_pred[:,i])* \\\n",
    "                               (theta_train[:,j]-theta_train_pred[:,j]))\n",
    "        training_var_unknown_mean.append(training_covariance)\n",
    "        \n",
    "        training_covariance_val = ((theta_val[:,i]-theta_val_pred[:,i])* \\\n",
    "                                   (theta_val[:,j]-theta_val_pred[:,j]))\n",
    "        training_var_unknown_mean_val.append(training_covariance_val)\n",
    "        \n",
    "        cov_dict[(i,j)] = count\n",
    "        count += 1\n",
    "        \n",
    "training_var_unknown_mean = np.array(training_var_unknown_mean).T\n",
    "training_var_unknown_mean_val = np.array(training_var_unknown_mean_val).T\n",
    "\n",
    "print(training_var_unknown_mean.shape)\n",
    "print(training_var_unknown_mean[0])\n",
    "\n",
    "n_covs = training_var_unknown_mean.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ccea3",
   "metadata": {},
   "source": [
    "Set up and train model on the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = demo.simple_leaky(n_dim, n_covs, learning_rate=1e-3)\n",
    "regression_var_unknown_mean = model_instance.model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = regression_var_unknown_mean.fit(Pk_train_scaled,\n",
    "                                          training_var_unknown_mean,\n",
    "                                          epochs=200, batch_size=32, shuffle=True,\n",
    "                                          validation_data = (Pk_val_scaled,\n",
    "                                                             training_var_unknown_mean_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7a19d",
   "metadata": {},
   "source": [
    "### Set up MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names_2_emu_param_names = {'sigma_8': 'sigma8_cold',\n",
    "                                 'omega_cold': 'omega_cold',\n",
    "                                 'h': 'hubble',\n",
    "                                 'n_s': 'ns'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137cadd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_cosmo_emu():\n",
    "    print(\"Setting up emulator cosmology\")\n",
    "    cosmo_params = {\n",
    "        #'omega_cold'    :  Om,\n",
    "        #'sigma8_cold'   :  sigma8, # if A_s is not specified\n",
    "        'omega_baryon'  :  param_dict_fixed['omega_baryon'],\n",
    "        'ns'            :  param_dict_fixed['n_s'],\n",
    "        #'hubble'        :  hubble,\n",
    "        'neutrino_mass' :  0.0,\n",
    "        'w0'            : -1.0,\n",
    "        'wa'            :  0.0,\n",
    "        'expfactor'     :  1\n",
    "    }\n",
    "    return cosmo_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793df3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emu = baccoemu.Lbias_expansion(verbose=False)\n",
    "emu = baccoemu.Lbias_expansion(nonlinear_emu_path='/dipc_storage/cosmosims/data_share/lbias_emulator/lbias_emulator2.0.0',\n",
    "                                     nonlinear_emu_details='details.pickle',\n",
    "                                     nonlinear_emu_field_name='NN_n',\n",
    "                                     nonlinear_emu_read_rotation=False)\n",
    "print(emu.emulator['nonlinear']['bounds'])\n",
    "cosmo_params = setup_cosmo_emu()\n",
    "bias_params = [1., 0., 0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16656ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_burn = 40\n",
    "n_steps = 200 # 50000\n",
    "n_walkers = 4 * n_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f53087",
   "metadata": {},
   "source": [
    "##### Check emu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_params = [0.0, 0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4456f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_error_pk[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 2, 1\n",
    "fig, axarr = plt.subplots(nrows, ncols, figsize=(6,6), sharex=True, height_ratios=[2,1])\n",
    "plt.subplots_adjust(hspace=0)\n",
    "\n",
    "colors = ['red', 'orange', 'green', 'blue', 'purple']\n",
    "\n",
    "for i in range(5):\n",
    "    for pp in range(len(param_names)):\n",
    "        emu_param_name = param_names_2_emu_param_names[param_names[pp]]\n",
    "        cosmo_params[emu_param_name] = theta[i][pp]\n",
    "    _, pk_model_unscaled, _ = emu.get_galaxy_real_pk(bias=bias_params, k=k, \n",
    "                                                        **cosmo_params)\n",
    "\n",
    "    label_true, label_emu = None, None\n",
    "    if i==0:\n",
    "        label_true = 'measured from map2map bias field'\n",
    "        label_emu = 'emulated at true theta'\n",
    "    \n",
    "    if i==0:\n",
    "        axarr[0].errorbar(k, Pk_train[i], yerr=gaussian_error_pk_train[i], \n",
    "                          ls='--', marker='o', markersize=6, alpha=0.5, label=label_true, color=colors[i])\n",
    "    else:\n",
    "        axarr[0].plot(k, Pk_train[i], ls='--', marker='o', markersize=6, alpha=0.5, label=label_true, color=colors[i])\n",
    "    axarr[0].plot(k, pk_model_unscaled, ls='-', alpha=0.5, label=label_emu, color=colors[i])\n",
    "    \n",
    "    axarr[1].plot(k, (pk_model_unscaled-Pk_train[i])/gaussian_error_pk_train[i], ls='-', alpha=0.5, color=colors[i])\n",
    "    axarr[1].axhline(0, color='grey', lw=0.5)\n",
    "    err_extra = 0.1*np.std(Pk_train, axis=0)\n",
    "    axarr[1].fill_between(k, -err_extra/gaussian_error_pk_train[i], \n",
    "                              err_extra/gaussian_error_pk_train[i], color='grey', alpha=0.1)\n",
    "\n",
    "plt.xscale('log')\n",
    "axarr[0].set_yscale('log')\n",
    "    \n",
    "axarr[1].set_ylim(-5, 5)\n",
    "    \n",
    "axarr[0].legend(fontsize=12)\n",
    "axarr[1].set_xlabel(r'$k \\,\\, [h \\,\\, {\\rm Mpc}^{-1}]$', fontsize=18)\n",
    "axarr[0].set_ylabel(r'$P(k) \\,\\, [h^{-3} \\,\\, {\\rm Mpc}^3]$', fontsize=18)    \n",
    "axarr[1].set_ylabel(r'$(P_\\text{emu}-P_\\text{m2m})/\\sigma_\\text{G,m2m}$', fontsize=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 2, 1\n",
    "fig, axarr = plt.subplots(nrows, ncols, figsize=(6,6), sharex=True, height_ratios=[2,1])\n",
    "plt.subplots_adjust(hspace=0)\n",
    "\n",
    "colors = ['red', 'orange', 'green', 'blue', 'purple']\n",
    "\n",
    "for i in range(5):\n",
    "    for pp in range(len(param_names)):\n",
    "        emu_param_name = param_names_2_emu_param_names[param_names[pp]]\n",
    "        cosmo_params[emu_param_name] = theta[i][pp]\n",
    "    _, pk_model_unscaled, _ = emu.get_galaxy_real_pk(bias=bias_params, k=k, \n",
    "                                                        **cosmo_params)\n",
    "    pk_model_scaled = scaler.scale(pk_model_unscaled)\n",
    "    label_true, label_emu = None, None\n",
    "    if i==0:\n",
    "        label_true = 'measured from map2map bias field'\n",
    "        label_emu = 'emulated at true theta'\n",
    "    \n",
    "    if i==0:\n",
    "        axarr[0].errorbar(k, Pk_train_scaled[i], yerr=gaussian_error_pk_train_scaled[i], \n",
    "                          ls='--', marker='o', markersize=6, alpha=0.5, label=label_true, color=colors[i])\n",
    "    else:\n",
    "        axarr[0].plot(k, Pk_train_scaled[i], ls='--', marker='o', markersize=6, alpha=0.5, label=label_true, color=colors[i])\n",
    "    axarr[0].plot(k, pk_model_scaled, ls='-', alpha=0.5, label=label_emu, color=colors[i])\n",
    "    \n",
    "    axarr[1].plot(k, (pk_model_scaled-Pk_train_scaled[i])/gaussian_error_pk_train_scaled[i], ls='-', alpha=0.5, color=colors[i])\n",
    "    axarr[1].axhline(0, color='grey', lw=0.5)\n",
    "    \n",
    "    err_extra = 0.1*np.std(Pk_train_scaled, axis=0)\n",
    "    axarr[1].fill_between(k, -err_extra/gaussian_error_pk_train_scaled[i], \n",
    "                              err_extra/gaussian_error_pk_train_scaled[i], color='grey', alpha=0.1)\n",
    "\n",
    "plt.xscale('log')\n",
    "#axarr[0].set_yscale('log')\n",
    "    \n",
    "axarr[1].set_ylim(-5, 5)\n",
    "    \n",
    "axarr[0].legend(fontsize=12)\n",
    "axarr[1].set_xlabel(r'$k \\,\\, [h \\,\\, {\\rm Mpc}^{-1}]$', fontsize=18)\n",
    "axarr[0].set_ylabel(r'$P(k) \\,\\, [h^{-3} \\,\\, {\\rm Mpc}^3]$', fontsize=18)    \n",
    "axarr[1].set_ylabel(r'$(P_\\text{emu}-P_\\text{m2m})/\\sigma_\\text{G,m2m}$', fontsize=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d29a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global pk_data, cov_inv\n",
    "\n",
    "def log_prior(theta):\n",
    "    for pp in range(len(param_names)):\n",
    "       if (theta[pp] < dict_bounds[param_names[pp]][0]) or (theta[pp] >= dict_bounds[param_names[pp]][1]):\n",
    "           return -np.inf\n",
    "    return 0.0\n",
    "\n",
    "def log_likelihood(theta):\n",
    "    for pp in range(len(param_names)):\n",
    "        emu_param_name = param_names_2_emu_param_names[param_names[pp]]\n",
    "        cosmo_params[emu_param_name] = theta[pp]\n",
    "    _, pk_model_unscaled, _ = emu.get_galaxy_real_pk(bias=bias_params, k=k, \n",
    "                                                **cosmo_params)\n",
    "    pk_model = scaler.scale(pk_model_unscaled)\n",
    "    diff = pk_data-pk_model\n",
    "    # print(theta)\n",
    "    # print(cosmo_params)\n",
    "    # print(pk_data)\n",
    "    # print(pk_model)\n",
    "    # print(cov_inv[0,0], cov_inv[1,1], cov_inv[2,2])\n",
    "    # print(-0.5*np.dot(diff,np.dot(cov_inv,diff)))\n",
    "    \n",
    "    # print()\n",
    "    return -0.5*np.dot(diff,np.dot(cov_inv,diff))\n",
    "\n",
    "def log_posterior(theta):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de3605",
   "metadata": {},
   "source": [
    "### Test on a model pulled directly from the training set (NOT held-out data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca4831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#idx_train_check = rng.choice(np.arange(len(theta_train)))\n",
    "idx_train_check = 17\n",
    "\n",
    "print(idx_train_check)\n",
    "theta_train_check = np.array([theta_train[idx_train_check]])\n",
    "print(theta_train_check)\n",
    "#Pk_train_check = np.array([Pk_train[idx_train_check]])\n",
    "Pk_train_scaled_check = np.array([Pk_train_scaled[idx_train_check]])\n",
    "\n",
    "predicted_mean_obs = regression.predict(np.atleast_2d(Pk_train_scaled_check))\n",
    "predicted_var_obs = (regression_var_unknown_mean.predict(np.atleast_2d(Pk_train_scaled_check))[0])\n",
    "\n",
    "print(predicted_var_obs)\n",
    "print(predicted_var_obs.shape)\n",
    "moment_network_param_cov = np.empty((n_params, n_params))\n",
    "\n",
    "for i in range(n_params):\n",
    "    for j in range(n_params):\n",
    "        moment_network_param_cov[i,j] = predicted_var_obs[cov_dict[(i,j)]]\n",
    "print(moment_network_param_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a403cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_network_samples = np.array(np.random.multivariate_normal(predicted_mean_obs[0],moment_network_param_cov,int(1e6)),dtype=np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7878765",
   "metadata": {},
   "source": [
    "#### Dynesty MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79daeb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_transform(u):\n",
    "\n",
    "    u_transformed = []\n",
    "    for pp in range(len(param_names)):\n",
    "        width = dict_bounds[param_names[pp]][1] - dict_bounds[param_names[pp]][0]\n",
    "        min_bound = dict_bounds[param_names[pp]][0]\n",
    "        \n",
    "        u_t = width*u[pp] + min_bound\n",
    "        u_transformed.append(u_t)           \n",
    "\n",
    "    return np.array(u_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c76444",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_gaussian = gaussian_error_pk_train_scaled[idx_train_check]\n",
    "err_extra = 0.1*np.std(Pk_train_scaled, axis=0)\n",
    "err = np.sqrt(err_gaussian**2 + err_extra**2)\n",
    "\n",
    "cov_inv = np.diag(1/err**2)\n",
    "pk_data = Pk_train_scaled[idx_train_check]\n",
    "\n",
    "n_threads = 8\n",
    "\n",
    "with dynesty.pool.Pool(n_threads, log_likelihood, prior_transform) as pool:\n",
    "\n",
    "    sampler = dynesty.NestedSampler(pool.loglike, pool.prior_transform, n_params, \n",
    "                                    nlive=10, bound='single')\n",
    "    sampler.run_nested(dlogz=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f092bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sampler.results\n",
    "samples_dynesty = results.samples_equal()\n",
    "print(samples_dynesty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dynesty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce141378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import plotting as dyplot\n",
    "\n",
    "fig, axes = plt.subplots(n_params, n_params, figsize=(3, 3))\n",
    "axes = axes.reshape((n_params, n_params)) \n",
    "fg, ax = dyplot.cornerplot(results, color='dodgerblue', #truths=np.zeros(n_params),\n",
    "                           truth_color='black', show_titles=True,\n",
    "                           quantiles=None, max_n_ticks=3,\n",
    "                           fig=(fig, axes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3040af",
   "metadata": {},
   "source": [
    "#### MCMC for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffee32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "theta_0 = np.array([[rng.uniform(low=dict_bounds[param_name][0],high=dict_bounds[param_name][1]) \n",
    "            for param_name in param_names] for _ in range(n_walkers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pk_data = Pk_train_scaled[idx_train_check]\n",
    "\n",
    "n_threads = 8\n",
    "start = time.time()\n",
    "if n_threads>1:\n",
    "    with Pool(processes=n_threads) as pool:\n",
    "        sampler_emcee = emcee.EnsembleSampler(n_walkers, n_params, log_posterior, pool=pool,\n",
    "                                    #args=(Pk_train_scaled[idx_train_check],cov_inv)\n",
    "                                    )\n",
    "        _ = sampler_emcee.run_mcmc(theta_0, n_steps, progress=True) \n",
    "else:\n",
    "    sampler_emcee = emcee.EnsembleSampler(n_walkers, n_params, log_posterior,\n",
    "                                #args=(Pk_train_scaled[idx_train_check],cov_inv)\n",
    "                                )\n",
    "    _ = sampler_emcee.run_mcmc(theta_0, n_steps, progress=True) \n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time: {end-start} s ({(end-start)/60} min)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c8322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_emcee = sampler_emcee.get_chain(discard=n_burn, flat=True,thin=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff8fc",
   "metadata": {},
   "source": [
    "### Plot contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e984a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_label_dict = {'omega_cold': r'$\\Omega_\\mathrm{m}$',\n",
    "                'sigma8_cold': r'$\\sigma_{8}$',\n",
    "                'sigma_8': r'$\\sigma_{8}$',\n",
    "                'hubble': r'$h$',\n",
    "                'h': r'$h$',\n",
    "                'ns': r'$n_\\mathrm{s}$',\n",
    "                'n_s': r'$n_\\mathrm{s}$',\n",
    "                'omega_baryon': r'$\\Omega_\\mathrm{b}$',}\n",
    "param_labels = [param_label_dict[param_name] for param_name in param_names]\n",
    "extents = [dict_bounds[param_name] for param_name in param_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37fdba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = chainconsumer.ChainConsumer()\n",
    "\n",
    "c.add_chain(chainconsumer.Chain(\n",
    "            samples=pd.DataFrame(moment_network_samples, columns=param_names),\n",
    "            name='Moment Network', color='blue')\n",
    "            )\n",
    "\n",
    "# checked that this gives the same as direct, once remove burn-in\n",
    "# chain_emcee = chainconsumer.Chain.from_emcee(sampler_emcee, param_names, discard=n_burn,\n",
    "#                                              name=\"MCMC (emcee)\", color=\"red\")\n",
    "# c.add_chain(chain_emcee)\n",
    "\n",
    "# c.add_chain(chainconsumer.Chain(\n",
    "#             samples=pd.DataFrame(samples_emcee, columns=param_names),\n",
    "#             name='MCMC (emcee)', color='purple', ls='--',\n",
    "#             smooth=1, bins=10)\n",
    "#             )\n",
    "\n",
    "c.add_chain(chainconsumer.Chain(\n",
    "            samples=pd.DataFrame(samples_dynesty, columns=param_names),\n",
    "            name='MCMC (Dynesty)', color='green', \n",
    "            smooth=1, bins=5)\n",
    "            )\n",
    "\n",
    "c.set_plot_config(\n",
    "    chainconsumer.PlotConfig(\n",
    "        flip=True,\n",
    "        labels=param_label_dict,\n",
    "        contour_label_font_size=12,\n",
    "        #extents=dict_bounds,\n",
    "    )\n",
    ")\n",
    "\n",
    "#c.set_override(chainconsumer.ChainConfig(smooth=1, bins=10))\n",
    "#c.set_override(chainconsumer.ChainConfig(smooth=1, bins=10))\n",
    "\n",
    "# c.configure(kde=[1.,None],sigmas = [1,2],\n",
    "#             contour_label_font_size = 11,\n",
    "#             label_font_size = 16, shade = False) \n",
    "\n",
    "truth_loc = dict(zip(param_names, theta_train_check[0]))\n",
    "c.add_truth(chainconsumer.Truth(location=truth_loc))\n",
    "\n",
    "fig = c.plotter.plot(figsize = (5,4) )\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(f'{plot_dir}/contours_traincheck{idx_train_check}{tag_fit}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91523c50",
   "metadata": {},
   "source": [
    "### Test on a model from the test set (held-out data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_test = 0\n",
    "predicted_mean_obs_test = regression.predict(np.atleast_2d(Pk_test_scaled[idx_test]))\n",
    "predicted_var_obs_test = (regression_var_unknown_mean.predict(np.atleast_2d(Pk_test_scaled[idx_test]))[0])\n",
    "\n",
    "moment_network_param_cov_test = np.empty((n_params, n_params))\n",
    "\n",
    "for i in range(n_params):\n",
    "    for j in range(n_params):\n",
    "        moment_network_param_cov_test[i,j] = predicted_var_obs_test[cov_dict[(i,j)]]\n",
    "print(moment_network_param_cov_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_network_samples_test = np.array(np.random.multivariate_normal(predicted_mean_obs_test[0],\n",
    "                                  moment_network_param_cov_test,int(1e6)),dtype=np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb34779",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_data = Pk_test_scaled[idx_test]\n",
    "\n",
    "n_threads = 8\n",
    "\n",
    "with dynesty.pool.Pool(n_threads, log_likelihood, prior_transform) as pool:\n",
    "\n",
    "    sampler_test = dynesty.NestedSampler(pool.loglike, pool.prior_transform, n_params, \n",
    "                                    nlive=20, bound='single')\n",
    "    sampler_test.run_nested(dlogz=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e11282",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = sampler_test.results\n",
    "samples_dynesty_test = results_test.samples_equal()\n",
    "print(samples_dynesty_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = chainconsumer.ChainConsumer()\n",
    "\n",
    "c.add_chain(chainconsumer.Chain(\n",
    "            samples=pd.DataFrame(moment_network_samples_test, columns=param_names),\n",
    "            name='Moment Network', color='blue')\n",
    "            )\n",
    "\n",
    "# c.add_chain(chainconsumer.Chain(\n",
    "#             samples=pd.DataFrame(samples_emcee, columns=param_names),\n",
    "#             name='MCMC (emcee)', color='purple', ls='--',\n",
    "#             smooth=1, bins=10)\n",
    "#             )\n",
    "\n",
    "c.add_chain(chainconsumer.Chain(\n",
    "            samples=pd.DataFrame(samples_dynesty_test, columns=param_names),\n",
    "            name='MCMC (Dynesty)', color='green', \n",
    "            smooth=2, bins=5)\n",
    "            )\n",
    "\n",
    "c.set_plot_config(\n",
    "    chainconsumer.PlotConfig(\n",
    "        flip=True,\n",
    "        labels=param_label_dict,\n",
    "        contour_label_font_size=12,\n",
    "        #extents=dict_bounds,\n",
    "    )\n",
    ")\n",
    "\n",
    "truth_loc = dict(zip(param_names, theta_test[idx_test]))\n",
    "c.add_truth(chainconsumer.Truth(location=truth_loc))\n",
    "\n",
    "fig = c.plotter.plot(figsize = (5,4) )\n",
    "if save_plots:\n",
    "    plt.savefig(f'{plot_dir}/contours_test{idx_test}{tag_fit}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb8ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bemuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
